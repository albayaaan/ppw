{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Crawling data PTA"
      ],
      "metadata": {
        "id": "cXyEnrE3oF5i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s42_t0_vnYnQ"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "def crawl_pta(url):\n",
        "\n",
        "    result = []\n",
        "    req = requests.get(url)\n",
        "    soup = BeautifulSoup(req.text, \"lxml\")\n",
        "\n",
        "    #find journal item\n",
        "    journal_links = soup.find_all(\"li\",{'data-id':'id-1'})\n",
        "\n",
        "    #looping through journal item\n",
        "    for idx,journal in enumerate(journal_links):\n",
        "        journal_dict = {}\n",
        "\n",
        "        #find journal title\n",
        "        title_journal = journal.find('a',{'class':'title'}).text\n",
        "\n",
        "        #find journal info\n",
        "        info_journal = journal.find_all('span')\n",
        "        writer_journal = info_journal[0].text.split(':')[1]\n",
        "        supervisor1_journal = info_journal[1].text.split(':')[1]\n",
        "        supervisor2_journal = info_journal[2].text.split(':')[1]\n",
        "\n",
        "        #find journal link\n",
        "        url_journal = journal.find('a',{'class':'gray button'}).get('href')\n",
        "\n",
        "        #find journal content in url\n",
        "        req_journal = requests.get(url_journal)\n",
        "        soup_journal = BeautifulSoup(req_journal.text, \"lxml\")\n",
        "\n",
        "        #find journal abstract\n",
        "        abstract_journal = soup_journal.find(\"p\",{'align':'justify'}).text\n",
        "\n",
        "        #wrap in dictionary\n",
        "        journal_dict['Judul'] = title_journal\n",
        "        journal_dict['Penulis'] = writer_journal\n",
        "        journal_dict['Pembimbing 1'] = supervisor1_journal\n",
        "        journal_dict['Pembimbing 2'] = supervisor2_journal\n",
        "        journal_dict['Abstrak'] = abstract_journal\n",
        "        result.append(journal_dict)\n",
        "\n",
        "    return result\n",
        "\n",
        "data = []\n",
        "for i in range (1,173):\n",
        "  result = crawl_pta('https://pta.trunojoyo.ac.id/c_search/byprod/10/%d'%i)\n",
        "  data += result\n",
        "\n",
        "# data = crawl_pta('https://pta.trunojoyo.ac.id/c_search/byprod/10')\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# saving the dataframe\n",
        "df.to_csv('crawl_result.csv')"
      ]
    }
  ]
}